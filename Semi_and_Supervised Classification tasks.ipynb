{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712988476753
        },
        "id": "hp6IrQCRlYtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############Common parameters  ######"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713043791390
        },
        "id": "3WOY6Dl6lYtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "No_Features=10  ### Number of features selected by PCA"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713049325881
        },
        "id": "FhdQarzglYta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "###Load tabular data\n",
        "LC_RF_PT = pd.read_excel(\"/home/azureuser/cloudfiles/code/Users/v-msalmanpou/Lung_Cancer/LC_DF_SPT.xlsx\" , engine='openpyxl',header=None)   ## Load you Lung Cancer Dataset\n",
        "HC_RF_PT = pd.read_excel(\"/home/azureuser/cloudfiles/code/Users/v-msalmanpou/Lung_Cancer/HC_DF_SPT.xlsx\" , engine='openpyxl',header=None)   ## Load you Head and Neck Cancer Dataset\n",
        "Lung_Outcome_all = pd.read_excel(\"/home/azureuser/cloudfiles/code/Users/v-msalmanpou/Lung_Cancer/LC_outcome.xlsx\" , engine='openpyxl',header=None)   ## Load you Lung ccancer Outcomes\n",
        "Lung_Outcome=Lung_Outcome_all.iloc[:, 2:]\n",
        "\n",
        "Length_LC_RF_PT= len(LC_RF_PT)\n",
        "Length_HC_RF_PT = len(HC_RF_PT)\n",
        "Length_Lung_Outcome = len(Lung_Outcome)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713049333191
        },
        "id": "4i55cYuOlYta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############### Concatinate Datasets for scaling ##############33"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713049333364
        },
        "id": "nro6FTBJlYtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "Concatinated_RF_PT = np.concatenate((LC_RF_PT, HC_RF_PT), axis=0)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713049333518
        },
        "id": "74xEDpeFlYtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############ Normalize datasets  #####################"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713049333692
        },
        "id": "1q_LtYtIlYtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "Scaled_Total_PT_RF = scaler.fit_transform(Concatinated_RF_PT)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total_Shape: (607, 1023)\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713049333859
        },
        "id": "TjA-ygijlYtd",
        "outputId": "de9bae4a-0f47-41d6-d45f-853db9da76cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############   Reduce feature size by feature selection algorithms o feature extraction algorithms  ###################3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713049334010
        },
        "id": "2KjWM1S6lYte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=No_Features)\n",
        "pca.fit(Scaled_Total_PT_RF)\n",
        "SelectedFeatures = pca.transform(Scaled_Total_PT_RF)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713050519870
        },
        "id": "9r45OuDrlYte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############## Split lung data for five fold cross validation and external testing  ####################3"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713050520086
        },
        "id": "ZeW5vMoulYtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### Split lung patinets from head and neck\n",
        "Split_LC_RF_PT = SelectedFeatures[0:Length_LC_RF_PT, :]\n",
        "Split_HC_RF_PT = SelectedFeatures[Length_LC_RF_PT:, :]\n",
        "\n",
        "X_train_L, X_test_L_EX, Y_train_L, Y_test_L_EX = train_test_split(Split_LC_RF_PT, Lung_Outcome, test_size=0.20)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713050520271
        },
        "id": "osAVc0jBlYtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############# Split Five folds ###############"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713050520527
        },
        "id": "BSISH5pWlYtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random_seed = 10\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Convert y_train to a NumPy array (if it's not already)\n",
        "Y_train_L = np.array(Y_train_L)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "#rf_classifier = RandomForestClassifier()\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=5,\n",
        "    criterion='gini',\n",
        "    max_depth=2,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=3,\n",
        "    max_features='auto',\n",
        "    bootstrap=True,\n",
        "    random_state=42\n",
        ")\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "# Initialize KFold with shuffling\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=random_seed)\n",
        "\n",
        "# Initialize an array to store cross-validation scores\n",
        "cv_scores_MPL_SSL= []\n",
        "cv_scores_MPL_SL= []\n",
        "cv_scores_MLP_SSL_EX = []\n",
        "cv_scores_MLP_SL_EX = []\n",
        "\n",
        "cv_scores_SVM_SSL= []\n",
        "cv_scores_SVM_SL= []\n",
        "cv_scores_SVM_SSL_EX = []\n",
        "cv_scores_SVM_SL_EX = []\n",
        "\n",
        "cv_scores_KNN_SSL= []\n",
        "cv_scores_KNN_SL= []\n",
        "cv_scores_KNN_SSL_EX = []\n",
        "cv_scores_KNN_SL_EX = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, val_index in kf.split(X_train_L):\n",
        "    # Split data into training and validation sets\n",
        "    X_train_fold, X_val_fold = X_train_L[train_index], X_train_L[val_index]\n",
        "    y_train_fold, y_val_fold = Y_train_L[train_index], Y_train_L[val_index]\n",
        "\n",
        "    # Train the classifier\n",
        "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Label HC datasets_Sudo Labeling\n",
        "    predictions_HC = rf_classifier.predict(Split_HC_RF_PT)\n",
        "    # Reshape predictions_HC to match the shape of y_train_fold\n",
        "    predictions_HC = predictions_HC.reshape(-1, 1)\n",
        "\n",
        "    # Concatenate predicted HC patients with LC data\n",
        "    Concatinated_X_RF_PT_Folds = np.concatenate((X_train_fold, Split_HC_RF_PT), axis=0)\n",
        "    Concatinated_Y_RF_PT_Folds = np.concatenate((y_train_fold, predictions_HC), axis=0)\n",
        "\n",
        "    ############Classifers Classifers Classifers Classifers Classifers Classifers  Classifers Classifers Classifers Classifers Classifers  ###########################\n",
        "\n",
        "   ### 1- MLP\n",
        "    ### Semisupervised\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    mlp_classifier_SSL = MLPClassifier(hidden_layer_sizes=(50, (50//2),2 ), activation='relu', solver='adam', max_iter=100, random_state=10)\n",
        "    #Internal\n",
        "    mlp_classifier_SSL.fit(Concatinated_X_RF_PT_Folds, Concatinated_Y_RF_PT_Folds)\n",
        "    y_predMLP = mlp_classifier_SSL.predict(X_val_fold)\n",
        "    accuracyMLP_SSL = accuracy_score(y_val_fold, y_predMLP)\n",
        "    cv_scores_MPL_SSL.append(accuracyMLP_SSL)\n",
        "    #External\n",
        "    y_predMLP = mlp_classifier_SSL.predict(X_test_L_EX)\n",
        "    accuracyMLP_SSL = accuracy_score(Y_test_L_EX, y_predMLP)\n",
        "    cv_scores_MLP_SSL_EX.append(accuracyMLP_SSL)\n",
        "\n",
        "    ### Supervised\n",
        "\n",
        "    mlp_classifier_SL = MLPClassifier(hidden_layer_sizes=(15, (10//2),2 ), activation='relu', solver='adam', max_iter=100, random_state=10)\n",
        "    #Internal\n",
        "    mlp_classifier_SL.fit(X_train_fold, y_train_fold)\n",
        "    y_predMLP = mlp_classifier_SL.predict(X_val_fold)\n",
        "    accuracyMLP_SL = accuracy_score(y_val_fold, y_predMLP)\n",
        "    cv_scores_MPL_SL.append(accuracyMLP_SL)\n",
        "    #External\n",
        "    y_predMLP = mlp_classifier_SL.predict(X_test_L_EX)\n",
        "    accuracyMLP_SL = accuracy_score(Y_test_L_EX, y_predMLP)\n",
        "    cv_scores_MLP_SL_EX.append(accuracyMLP_SL)\n",
        "############################################################\n",
        "   ### 2- SVM\n",
        "    ### Semisupervised\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    svm_clf_SSL = SVC(kernel='rbf', C=0.001, gamma='auto', random_state=52)\n",
        "    #svm_clf_SSL = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "\n",
        "    #Internal\n",
        "    svm_clf_SSL.fit(Concatinated_X_RF_PT_Folds, Concatinated_Y_RF_PT_Folds)\n",
        "    SVMy_pred = svm_clf_SSL.predict(X_val_fold)\n",
        "    accuracySVM_SSL = accuracy_score(y_val_fold, SVMy_pred)\n",
        "    cv_scores_SVM_SSL.append(accuracySVM_SSL)\n",
        "    #External\n",
        "    y_predSVM = svm_clf_SSL.predict(X_test_L_EX)\n",
        "    accuracySVM_SSL = accuracy_score(Y_test_L_EX, y_predSVM)\n",
        "    cv_scores_SVM_SSL_EX.append(accuracySVM_SSL)\n",
        "\n",
        "    ### Supervised\n",
        "    svm_clf_SL = SVC(kernel='poly', C=1.0, gamma='auto', random_state=110)\n",
        "    #Internal\n",
        "    svm_clf_SL.fit(X_train_fold, y_train_fold)\n",
        "    SVMy_pred1 = svm_clf_SL.predict(X_val_fold)\n",
        "    accuracySVM_SL = accuracy_score(y_val_fold, SVMy_pred1)\n",
        "    cv_scores_SVM_SL.append(accuracySVM_SL)\n",
        "    #External\n",
        "    y_predSVM2 = svm_clf_SL.predict(X_test_L_EX)\n",
        "    accuracySVM_SL = accuracy_score(Y_test_L_EX, y_predSVM2)\n",
        "    cv_scores_SVM_SL_EX.append(accuracySVM_SL)\n",
        "\n",
        "### 3- KNN\n",
        "    ### Semisupervised\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    KNN_clf_SSL = KNeighborsClassifier(n_neighbors=25)  # Specify the number of neighbors (k)\n",
        "\n",
        "\n",
        "    #Internal\n",
        "    KNN_clf_SSL.fit(Concatinated_X_RF_PT_Folds, Concatinated_Y_RF_PT_Folds)\n",
        "    KNNy_pred = KNN_clf_SSL.predict(X_val_fold)\n",
        "    accuracyKNN_SSL = accuracy_score(y_val_fold, KNNy_pred)\n",
        "    cv_scores_KNN_SSL.append(accuracyKNN_SSL)\n",
        "    #External\n",
        "    y_predKNN = KNN_clf_SSL.predict(X_test_L_EX)\n",
        "    accuracyKNN_SSL = accuracy_score(Y_test_L_EX, y_predKNN)\n",
        "    cv_scores_KNN_SSL_EX.append(accuracyKNN_SSL)\n",
        "\n",
        "    ### Supervised\n",
        "    KNN_clf_SL = KNeighborsClassifier(n_neighbors=1)  # Specify the number of neighbors (k)\n",
        "\n",
        "    #Internal\n",
        "    KNN_clf_SL.fit(X_train_fold, y_train_fold)\n",
        "    KNNy_pred = KNN_clf_SL.predict(X_val_fold)\n",
        "    accuracyKNN_SL = accuracy_score(y_val_fold, KNNy_pred)\n",
        "    cv_scores_KNN_SL.append(accuracyKNN_SL)\n",
        "    #External\n",
        "    y_predKNN = KNN_clf_SL.predict(X_test_L_EX)\n",
        "    accuracyKNN_SL = accuracy_score(Y_test_L_EX, y_predKNN)\n",
        "    cv_scores_KNN_SL_EX.append(accuracyKNN_SL)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------\")\n",
        "print(\"MLP\")\n",
        "print (\"    -------  Average cross validation--------\")\n",
        "\n",
        "print(\"Mean accuracy_MLP_SSL:\", [(round(np.mean(cv_scores_MPL_SSL),2)),round(np.std(cv_scores_MPL_SSL),2)])\n",
        "\n",
        "print(\"Mean accuracy_MLP_SL:\", [round(np.mean(cv_scores_MPL_SL),2),round(np.std(cv_scores_MPL_SL),2)])\n",
        "\n",
        "print(\"Mean accuracy_NestedXT_MLP_SSL:\", [round(np.mean(cv_scores_MLP_SSL_EX),2),round(np.std(cv_scores_MLP_SSL_EX),2)])\n",
        "\n",
        "print(\"Mean accuracy_NestedXT_MLP_SL:\", [round(np.mean(cv_scores_MLP_SL_EX),2),round(np.std(cv_scores_MLP_SL_EX),2)])\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------\")\n",
        "print(\"SVM\")\n",
        "\n",
        "print(\"Mean accuracy_SVM_SSL:\", [(round(np.mean(cv_scores_SVM_SSL),2)),round(np.std(cv_scores_SVM_SSL),2)])\n",
        "\n",
        "print(\"Mean accuracy_SVM_SL:\", [round(np.mean(cv_scores_SVM_SL),2),round(np.std(cv_scores_SVM_SL),2)])\n",
        "\n",
        "print(\"Mean accuracy_NestedXT_SVM_SSL:\", [round(np.mean(cv_scores_SVM_SSL_EX),2),round(np.std(cv_scores_SVM_SSL_EX),2)])\n",
        "\n",
        "print(\"Mean accuracy_NestedXT_SVM_SL:\", [round(np.mean(cv_scores_SVM_SL_EX),2),round(np.std(cv_scores_SVM_SL_EX),2)])\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"KNN\")\n",
        "\n",
        "print(\"Mean accuracy_KNN_SSL:\", [(round(np.mean(cv_scores_KNN_SSL),2)),round(np.std(cv_scores_KNN_SSL),2)])\n",
        "\n",
        "print(\"Mean accuracy_KNN_SL:\", [round(np.mean(cv_scores_KNN_SL),2),round(np.std(cv_scores_KNN_SL),2)])\n",
        "\n",
        "print(\"Mean accuracy_NestedXT_KNN_SSL:\", [round(np.mean(cv_scores_KNN_SSL_EX),2),round(np.std(cv_scores_KNN_SSL_EX),2)])\n",
        "\n",
        "print(\"Mean accuracy_NestedXT_KNN_SL:\", [round(np.mean(cv_scores_KNN_SL_EX),2),round(np.std(cv_scores_KNN_SL_EX),2)])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713050522625
        },
        "id": "xtV8BUVTlYth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Setting bold font globally\n",
        "plt.rcParams['font.weight'] = 'bold'\n",
        "plt.rcParams['axes.labelweight'] = 'bold'\n",
        "plt.rcParams['axes.titleweight'] = 'bold'\n",
        "\n",
        "# Sample data for plotting or other operations\n",
        "stores = ['MRI', 'SVM', 'KNN']\n",
        "\n",
        "\n",
        "\n",
        "sales_2019 = [0.85,0.81,0.83]\n",
        "sales_2020 = [0.5,0.59,0.6]\n",
        "\n",
        "# Standard deviations for the sample data\n",
        "std_2019 = [0.05,0.06,0.06]\n",
        "std_2020 = [0.05,0.1,0.05]\n",
        "# Create an index for each tick position\n",
        "x = np.arange(len(stores))\n",
        "\n",
        "# Bar width\n",
        "width = 0.40\n",
        "\n",
        "# Creating the bars with error bars\n",
        "fig, ax = plt.subplots()\n",
        "bars1 = ax.bar(x - width/2, sales_2019, width, label='Semi-supervised', yerr=std_2019, capsize=2, color='green')\n",
        "bars2 = ax.bar(x + width/2, sales_2020, width, label='Supervised', yerr=std_2020, capsize=2, color='red')\n",
        "\n",
        "# Adding some text for labels, title, and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy', fontsize=20)  # Increased font size for y-axis label\n",
        "ax.set_title('DRF-PET', fontsize=20)  # Increased title font size for consistency\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(stores, fontsize=16, fontweight='bold')  # Maintaining increased font size for x-tick labels\n",
        "\n",
        "# Set y-axis limits\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "# Increase font size of y-axis tick labels\n",
        "ax.tick_params(axis='y', labelsize=14)  # Set font size for y-axis tick labels\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "# Adding grid\n",
        "ax.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "fig.savefig(r'/home/azureuser/cloudfiles/code/Users/v-msalmanpou/Salmanpour/Figures/DRF-PET.png')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1713078541538
        },
        "id": "7jcph7DTlYtj"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}