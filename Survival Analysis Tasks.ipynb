{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977029b-1d90-4aa2-9f47-e0131cbe960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sksurv.datasets import load_veterans_lung_cancer\n",
    "from sksurv.ensemble import RandomSurvivalForest, ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "from sksurv.svm import FastSurvivalSVM\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cd379-492e-4a5c-8ea0-b09c7ec2d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Font settings for plots\n",
    "font_size = 16\n",
    "mlp.rcParams['figure.figsize'] = (8, 6)\n",
    "mlp.rcParams['figure.labelsize'] = 'large'\n",
    "font = {'weight' : 'bold',\n",
    "        'size' : font_size}\n",
    "\n",
    "mlp.rc('font', **font)\n",
    "font_label = font_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c12ec-e0c6-4ef1-a18a-2f644c4f4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of datasets\n",
    "dataset_names = ['LC_DF_SCT', 'LC_DF_SPT', 'LC_RF_CT', 'LC_RF_PT']\n",
    "result_names = ['DRF-CT', 'DRF-PET', 'HRF-CT', 'HRF-PET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7481c4-44c9-49c7-a772-8df487a239b2",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087927c0-eafc-44a2-86b8-fad84386ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HyperParametters for Random Survival Forest, Fast Survival SVM and Component-wise Gradient Boosting Survival Analysis\n",
    "\n",
    "# Random Survival Forest\n",
    "rsf = RandomSurvivalForest(n_estimators=10,\n",
    "                           min_samples_split=5,\n",
    "                           min_samples_leaf=10,\n",
    "                           max_features=\"sqrt\",\n",
    "                           n_jobs=-1,\n",
    "                           random_state=42)\n",
    "\n",
    "# Fast Survival SVM\n",
    "fssvm = FastSurvivalSVM(max_iter=512, tol=1e-6, random_state=42)\n",
    "\n",
    "# Component-wise Gradient Boosting Survival Analysis\n",
    "cwgbsa = ComponentwiseGradientBoostingSurvivalAnalysis(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48196cb8-35c2-4fe7-a2e6-93fe04d73a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Five folds\n",
    "# Assuming X is your feature matrix and y is your target vector\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa0883-a5fc-4f84-a537-1f2f9fcf63af",
   "metadata": {},
   "source": [
    "## 1. Random Survival Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a3751-a5b1-4d44-a24c-634fbc19c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Random Survival Forest #################################\n",
    "\n",
    "# Add RFS Algorithm reported Results to its Data Frame\n",
    "df_reported_results_rsf = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
    "                                                'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
    "\n",
    "# Compute statistics features for all datasets with RFS algorithm\n",
    "for index_name in range(4):\n",
    "    \n",
    "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
    "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
    "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
    "\n",
    "    # Convert days to years\n",
    "    years = y['Duration'].astype('float') / 365\n",
    "\n",
    "    # Convert the structured array y to a boolean array\n",
    "    event = y['Censor'].astype(bool)\n",
    "    time = y['Duration'].values\n",
    "    \n",
    "    # Define PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    \n",
    "    # Prepare the data for the model\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    \n",
    "    # Split Data\n",
    "    X_train = X[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    event_train = event[:train_size]\n",
    "    time_train = time[:train_size]\n",
    "    event_test_external = event[train_size:]\n",
    "    time_test_external = time[train_size:]\n",
    "    \n",
    "    # Dimention Reduction with PCA\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_test = min_max_scaler.transform(X_test)\n",
    "    \n",
    "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
    "                        dtype=[('Censor', bool), ('Duration', float)])\n",
    "    \n",
    "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
    "                       dtype=[('Censor', bool), ('Duration', float)])\n",
    "\n",
    "    # Add Algorithm internal and external Results to its Data Frame\n",
    "    df_internal_results_rsf = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
    "\n",
    "    # Risk Scores for 5-fold and external test\n",
    "    risk_scores_folds = []\n",
    "    risk_scores_test_external = []\n",
    " \n",
    "    # Fit the model\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
    "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "        # Determine internal Event and Time\n",
    "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
    "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
    "        \n",
    "        # Train Model\n",
    "        rsf.fit(X_train_in, y_train_in)\n",
    "    \n",
    "        ################################# Predicting survival - Internal Test #################################\n",
    "        \n",
    "        # Predict\n",
    "        risk_scores_internal = rsf.predict(X_test_in)\n",
    "        for item in risk_scores_internal.tolist():\n",
    "            risk_scores_folds.append(item)\n",
    "        \n",
    "        # C-Index\n",
    "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
    "        c_index_internal = result_internal[0]\n",
    "        \n",
    "        # Log-rank Test\n",
    "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
    "        idx_internal = group_labels_internal == 1\n",
    "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
    "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
    "        \n",
    "        # Compute log-rank test\n",
    "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
    "        # Compute P-Value test\n",
    "        p_value_internal = test_result_internal.p_value\n",
    "    \n",
    "        ################################# Predicting survival - External Test #################################\n",
    "        \n",
    "        # Predict\n",
    "        risk_scores_external = rsf.predict(X_test)\n",
    "        for item in risk_scores_external.tolist():\n",
    "            risk_scores_test_external.append(item)\n",
    "        \n",
    "        # C-Index\n",
    "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
    "        c_index_external = result_external[0]\n",
    "        \n",
    "        # Log-rank Test\n",
    "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
    "        idx_external = group_labels_external == 1\n",
    "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
    "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
    "        \n",
    "        # Compute log-rank test\n",
    "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
    "        # Compute P-Value test\n",
    "        p_value_external = test_result_external.p_value\n",
    "    \n",
    "        # Add Internal and External Results to Data Frame\n",
    "        df_internal_results_rsf.loc[len(df_internal_results_rsf)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
    "    \n",
    "    # Add Internal and External Results to Data Frame\n",
    "    df_internal_results_rsf.to_csv(os.path.join('Results', 'RSF_{}-Results.csv'.format(str(result_names[index_name]))))\n",
    "\n",
    "    \n",
    "    ############################ P-Value #########################################################################\n",
    "    \n",
    "    # Log-rank Test\n",
    "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
    "    idx = group_labels == 1\n",
    "    time1, event1 = time_train[idx], event_train[idx]\n",
    "    time2, event2 = time_train[~idx], event_train[~idx]\n",
    "    \n",
    "    # Compute log-rank test\n",
    "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
    "    # Compute P-Value test\n",
    "    p_value_train = train_result.p_value\n",
    "    \n",
    "    ############################################ Save Results #####################################################\n",
    "    \n",
    "    # Add C-Indexes and P-values to data frame\n",
    "    mean_cindex_internal = df_internal_results_rsf['C-Index internal'].mean()\n",
    "    std_cindex_internal = df_internal_results_rsf['C-Index internal'].std()\n",
    "    mean_cindex_external = df_internal_results_rsf['C-Index External'].mean()\n",
    "    std_cindex_external = df_internal_results_rsf['C-Index External'].std()\n",
    "    pvalue_external = df_internal_results_rsf['P-Value External'].min()    \n",
    "    \n",
    "    ############################################## Draw Kaplan Mier ##############################################\n",
    "    \n",
    "    # Determine high and low risk groups\n",
    "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
    "    threshold = np.percentile(risk_scores_combined, 50)\n",
    "\n",
    "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
    "    \n",
    "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
    "    low_risk = y_combined[risk_scores_combined < threshold]\n",
    "    \n",
    "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
    "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
    "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
    "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
    "    \n",
    "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
    "        # Calculate the Kaplan-Meier estimates for the two groups\n",
    "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
    "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
    "        \n",
    "        # Compute P-value combined data\n",
    "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
    "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
    "        pvalue_combined = results_pvalue_combined.p_value\n",
    "\n",
    "        # Compute c-index combined data\n",
    "        event_combined = np.array([tup[0] for tup in y_combined])\n",
    "        time_combined = np.array([tup[1] for tup in y_combined])\n",
    "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
    "        c_index_combined = results_cindex_combined[0]\n",
    "        \n",
    "        kmf1 = KaplanMeierFitter()\n",
    "        kmf2 = KaplanMeierFitter()\n",
    "        \n",
    "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
    "        \n",
    "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
    "    \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
    "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
    "        plt.title(\"Kaplan-Meier Survival Curve\", fontsize=font_label, fontweight='bold')\n",
    "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
    "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
    "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
    "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5, zorder=-1000)\n",
    "        \n",
    "        add_at_risk_counts(kmf1, kmf2 , ax=ax)\n",
    "        \n",
    "        fig.savefig(os.path.join('Plots', 'RSF_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
    "\n",
    "    #########################################################################################################\n",
    "\n",
    "    # Add Reported Results to its Data Frame\n",
    "    df_reported_results_rsf.loc[len(df_reported_results_rsf)] = [result_names[index_name], 'RSF', mean_cindex_internal, std_cindex_internal,\n",
    "                                                                 mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
    "                                                                 c_index_combined, pvalue_combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fdf254-5851-4f4a-a597-59cdca1af59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1514ca5d-fb3d-426b-a929-749bab17d779",
   "metadata": {},
   "source": [
    "## Fast Survival SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de60be-e4e4-449a-9ef2-f171d6577cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Random Survival Forest #################################\n",
    "\n",
    "# Data Frame for Add RFS Algorithm reported Results\n",
    "df_reported_results_fssvm = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
    "                                                  'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
    "\n",
    "# Compute statistics features for all datasets with RFS algorithm\n",
    "for index_name in range(4):\n",
    "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
    "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
    "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
    "\n",
    "    # Convert days to years\n",
    "    years = y['Duration'].astype('float') / 365\n",
    "    \n",
    "    # Convert the structured array y to a boolean array\n",
    "    event = y['Censor'].astype(bool)\n",
    "    time = y['Duration'].values\n",
    "    \n",
    "    # Define PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    \n",
    "    # Prepare the data for the model\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    \n",
    "    # Split Data\n",
    "    X_train = X[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    event_train = event[:train_size]\n",
    "    time_train = time[:train_size]\n",
    "    event_test_external = event[train_size:]\n",
    "    time_test_external = time[train_size:]\n",
    "    \n",
    "    # Dimention Reduction with PCA\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_test = min_max_scaler.transform(X_test)\n",
    "    \n",
    "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
    "                        dtype=[('Censor', bool), ('Duration', float)])\n",
    "    \n",
    "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
    "                       dtype=[('Censor', bool), ('Duration', float)])\n",
    "\n",
    "    # Add Algorithm internal and external Results to its Data Frame\n",
    "    df_internal_results_fssvm = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
    "\n",
    "    # Risk Scores for 5-fold and external test\n",
    "    risk_scores_folds = []\n",
    "    risk_scores_test_external = []\n",
    "\n",
    "    # Fit the model\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
    "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "        # Determine internal Event and Time\n",
    "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
    "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
    "        \n",
    "        # Train Model\n",
    "        fssvm.fit(X_train_in, y_train_in)\n",
    "    \n",
    "        ################################# Predicting survival - Internal Test #################################\n",
    "        \n",
    "        # Predict\n",
    "        risk_scores_internal = fssvm.predict(X_test_in)\n",
    "        for item in risk_scores_internal.tolist():\n",
    "            risk_scores_folds.append(item)\n",
    "        \n",
    "        # C-Index\n",
    "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
    "        c_index_internal = result_internal[0]\n",
    "        \n",
    "        # Log-rank Test\n",
    "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
    "        idx_internal = group_labels_internal == 1\n",
    "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
    "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
    "        \n",
    "        # Compute log-rank test\n",
    "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
    "        # Compute P-Value test\n",
    "        p_value_internal = test_result_internal.p_value\n",
    "    \n",
    "        ################################# Predicting survival - External Test #################################\n",
    "        \n",
    "        # Predict\n",
    "        risk_scores_external = fssvm.predict(X_test)\n",
    "        for item in risk_scores_external.tolist():\n",
    "            risk_scores_test_external.append(item)\n",
    "        \n",
    "        # C-Index\n",
    "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
    "        c_index_external = result_external[0]\n",
    "        \n",
    "        # Log-rank Test\n",
    "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
    "        idx_external = group_labels_external == 1\n",
    "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
    "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
    "        \n",
    "        # Compute log-rank test\n",
    "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
    "        # Compute P-Value test\n",
    "        p_value_external = test_result_external.p_value\n",
    "    \n",
    "        # Add Internal and External Results to Data Frame\n",
    "        df_internal_results_fssvm.loc[len(df_internal_results_fssvm)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
    "    \n",
    "    # Add Internal and External Results to Data Frame\n",
    "    df_internal_results_fssvm.to_csv(os.path.join('Results', 'FSSVM_{}-Results.csv'.format(str(result_names[index_name]))))\n",
    "\n",
    "    \n",
    "    ############################ P-Value #########################################################################\n",
    "    \n",
    "    # Log-rank Test\n",
    "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
    "    idx = group_labels == 1\n",
    "    time1, event1 = time_train[idx], event_train[idx]\n",
    "    time2, event2 = time_train[~idx], event_train[~idx]\n",
    "    \n",
    "    # Compute log-rank test\n",
    "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
    "    # Compute P-Value test\n",
    "    p_value_train = train_result.p_value\n",
    "    \n",
    "    ############################################ Save Results #####################################################\n",
    "    \n",
    "    # Add C-Indexes and P-values to its Data Frame\n",
    "    mean_cindex_internal = df_internal_results_fssvm['C-Index internal'].mean()\n",
    "    std_cindex_internal = df_internal_results_fssvm['C-Index internal'].std()\n",
    "    mean_cindex_external = df_internal_results_fssvm['C-Index External'].mean()\n",
    "    std_cindex_external = df_internal_results_fssvm['C-Index External'].std()\n",
    "    pvalue_external = df_internal_results_fssvm['P-Value External'].min()    \n",
    "    \n",
    "    ############################################## Draw Kaplan Mier ##############################################\n",
    "    \n",
    "    # Determine high and low risk groups\n",
    "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
    "    threshold = np.percentile(risk_scores_combined, 50)\n",
    "\n",
    "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
    "    \n",
    "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
    "    low_risk = y_combined[risk_scores_combined < threshold]\n",
    "    \n",
    "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
    "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
    "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
    "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
    "    \n",
    "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
    "        # Calculate the Kaplan-Meier estimates for the two groups\n",
    "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
    "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
    "        \n",
    "        # Compute P-value combined data\n",
    "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
    "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
    "        pvalue_combined = results_pvalue_combined.p_value\n",
    "\n",
    "        # Compute c-index combined data\n",
    "        event_combined = np.array([tup[0] for tup in y_combined])\n",
    "        time_combined = np.array([tup[1] for tup in y_combined])\n",
    "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
    "        c_index_combined = results_cindex_combined[0]\n",
    "        \n",
    "        kmf1 = KaplanMeierFitter()\n",
    "        kmf2 = KaplanMeierFitter()\n",
    "        \n",
    "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
    "        \n",
    "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
    "    \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
    "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
    "        plt.title(\"Kaplan-Meier Survival Curve\", fontsize=font_label, fontweight='bold')\n",
    "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
    "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
    "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
    "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5,zorder=-1000)\n",
    "        \n",
    "        add_at_risk_counts(kmf1, kmf2 , ax=ax)\n",
    "        # plt.tight_layout()\n",
    "        \n",
    "        fig.savefig(os.path.join('Plots', 'FSSVM_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
    "\n",
    "    #########################################################################################################\n",
    "\n",
    "    # Add Reported Results to its Data Frame\n",
    "    df_reported_results_fssvm.loc[len(df_reported_results_fssvm)] = [result_names[index_name], 'FSSVM', mean_cindex_internal, std_cindex_internal,\n",
    "                                                                     mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
    "                                                                     c_index_combined, pvalue_combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7714bbc-b267-4d6c-8a9b-c4e60051f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1307e48-8b68-4850-8ba3-d8c5f97179bd",
   "metadata": {},
   "source": [
    "## Component-wise Gradient Boosting Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a141c-5f01-45ac-9d52-3717ee5a3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Random Survival Forest #################################\n",
    "\n",
    "# Data Frame for Add RFS Algorithm reported Results\n",
    "df_reported_results_cwgbsa = pd.DataFrame(columns=['Dataset', 'SRA', 'Mean C-Index Internal', 'Std C-Index Internal', 'Mean C-Index External',\n",
    "                                                   'Std C-Index External', '5-Folds P-Value', 'P-value External', 'Combined C-Index', 'Combined P-value'])\n",
    "\n",
    "# Compute statistics features for all datasets with RFS algorithm\n",
    "for index_name in range(4):\n",
    "    # Load a dataset (example: Veterans' Lung Cancer trial)\n",
    "    X = pd.read_csv(os.path.join('Data', '{}.csv'.format(str(dataset_names[index_name]))), header=None)\n",
    "    y = pd.read_csv(os.path.join('Data', 'COX_OUTCOME.csv'))\n",
    "\n",
    "    # Convert days to years\n",
    "    years = y['Duration'].astype('float') / 365\n",
    "    \n",
    "    # Convert the structured array y to a boolean array\n",
    "    event = y['Censor'].astype(bool)\n",
    "    time = y['Duration'].values\n",
    "    \n",
    "    # Define PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    \n",
    "    # Prepare the data for the model\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    \n",
    "    # Split Data\n",
    "    X_train = X[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    event_train = event[:train_size]\n",
    "    time_train = time[:train_size]\n",
    "    event_test_external = event[train_size:]\n",
    "    time_test_external = time[train_size:]\n",
    "    \n",
    "    # Dimention Reduction with PCA\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_test = min_max_scaler.transform(X_test)\n",
    "    \n",
    "    y_train = np.array([(e, t) for e, t in zip(event_train, time_train)],\n",
    "                        dtype=[('Censor', bool), ('Duration', float)])\n",
    "    \n",
    "    y_test = np.array([(e, t) for e, t in zip(event_test_external, time_test_external)],\n",
    "                       dtype=[('Censor', bool), ('Duration', float)])\n",
    "\n",
    "    # Add Algorithm internal and external Results to its Data Frame\n",
    "    df_internal_results_cwgbsa = pd.DataFrame(columns=['C-Index internal', 'C-Index External', 'P-Value Internal', 'P-Value External'])\n",
    "\n",
    "    # Risk Scores for 5-fold and external test\n",
    "    risk_scores_folds = []\n",
    "    risk_scores_test_external = []\n",
    " \n",
    "    # Fit the model\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_in, X_test_in = X_train[train_index], X_train[test_index]\n",
    "        y_train_in, y_test_in = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "        # Determine internal Event and Time\n",
    "        event_test_internal = np.array([tup[0] for tup in y_test_in])\n",
    "        time_test_internal = np.array([tup[1] for tup in y_test_in])\n",
    "        \n",
    "        # Train Model\n",
    "        cwgbsa.fit(X_train_in, y_train_in)\n",
    "    \n",
    "        ################################# Predicting survival - Internal Test #################################\n",
    "        \n",
    "        # Predict\n",
    "        risk_scores_internal = cwgbsa.predict(X_test_in)\n",
    "        for item in risk_scores_internal.tolist():\n",
    "            risk_scores_folds.append(item)\n",
    "        \n",
    "        # C-Index\n",
    "        result_internal = concordance_index_censored(event_test_internal, time_test_internal, risk_scores_internal)\n",
    "        c_index_internal = result_internal[0]\n",
    "        \n",
    "        # Log-rank Test\n",
    "        group_labels_internal = np.random.choice([0, 1], size=X_test_in.shape[0], replace=True)  # Example groups\n",
    "        idx_internal = group_labels_internal == 1\n",
    "        time1_internal, event1_internal = time_test_internal[idx_internal], event_test_internal[idx_internal]\n",
    "        time2_internal, event2_internal = time_test_internal[~idx_internal], event_test_internal[~idx_internal]\n",
    "        \n",
    "        # Compute log-rank test\n",
    "        test_result_internal = logrank_test(time1_internal, time2_internal, event_observed_A=event1_internal, event_observed_B=event2_internal)\n",
    "        # Compute P-Value test\n",
    "        p_value_internal = test_result_internal.p_value\n",
    "    \n",
    "        ################################# Predicting survival - External Test #################################\n",
    "        \n",
    "        # Predict\n",
    "        risk_scores_external = cwgbsa.predict(X_test)\n",
    "        for item in risk_scores_external.tolist():\n",
    "            risk_scores_test_external.append(item)\n",
    "        \n",
    "        # C-Index\n",
    "        result_external = concordance_index_censored(event_test_external, time_test_external, risk_scores_external)\n",
    "        c_index_external = result_external[0]\n",
    "        \n",
    "        # Log-rank Test (Example for two hypothetical groups)\n",
    "        group_labels_external = np.random.choice([0, 1], size=X_test.shape[0], replace=True)  # Example groups\n",
    "        idx_external = group_labels_external == 1\n",
    "        time1_external, event1_external = time_test_external[idx_external], event_test_external[idx_external]\n",
    "        time2_external, event2_external = time_test_external[~idx_external], event_test_external[~idx_external]\n",
    "        \n",
    "        # Compute log-rank test\n",
    "        test_result_external = logrank_test(time1_external, time2_external, event_observed_A=event1_external, event_observed_B=event2_external)\n",
    "        # Compute P-Value test\n",
    "        p_value_external = test_result_external.p_value\n",
    "    \n",
    "        # Add Internal and External Results to Data Frame\n",
    "        df_internal_results_cwgbsa.loc[len(df_internal_results_cwgbsa)] = [c_index_internal, c_index_external, p_value_internal, p_value_external]\n",
    "    \n",
    "    # Add Internal and External Results to Data Frame\n",
    "    df_internal_results_cwgbsa.to_csv(os.path.join('Results', 'CWGBSA_{}-Results.csv'.format(str(result_names[index_name]))))\n",
    "\n",
    "    \n",
    "    ############################ P-Value #########################################################################\n",
    "    \n",
    "    # Log-rank Test\n",
    "    group_labels = np.random.choice([0, 1], size=X_train.shape[0], replace=True)  # Example groups\n",
    "    idx = group_labels == 1\n",
    "    time1, event1 = time_train[idx], event_train[idx]\n",
    "    time2, event2 = time_train[~idx], event_train[~idx]\n",
    "    \n",
    "    # Compute log-rank test\n",
    "    train_result = logrank_test(time1, time2, event_observed_A=event1, event_observed_B=event2)\n",
    "    # Compute P-Value test\n",
    "    p_value_train = train_result.p_value\n",
    "    \n",
    "    ############################################ Save Results #####################################################\n",
    "    \n",
    "    # Add C-Indexes and P-values to its Data Frame\n",
    "    mean_cindex_internal = df_internal_results_cwgbsa['C-Index internal'].mean()\n",
    "    std_cindex_internal = df_internal_results_cwgbsa['C-Index internal'].std()\n",
    "    mean_cindex_external = df_internal_results_cwgbsa['C-Index External'].mean()\n",
    "    std_cindex_external = df_internal_results_cwgbsa['C-Index External'].std()\n",
    "    pvalue_external = df_internal_results_cwgbsa['P-Value External'].min()    \n",
    "    \n",
    "    ############################################## Draw Kaplan Mier ##############################################\n",
    "    \n",
    "    # Determine high and low risk groups\n",
    "    risk_scores_combined = np.array(risk_scores_folds + risk_scores_test_external)\n",
    "    threshold = np.percentile(risk_scores_combined, 50)\n",
    "\n",
    "    y_combined = np.array(y_train.tolist() + (y_test.tolist() * 5))\n",
    "    \n",
    "    high_risk = y_combined[risk_scores_combined >= threshold]\n",
    "    low_risk = y_combined[risk_scores_combined < threshold]\n",
    "    \n",
    "    high_risk_event = np.array([tup[0] for tup in high_risk])\n",
    "    high_risk_time = np.array([tup[1] for tup in high_risk])\n",
    "    low_risk_event = np.array([tup[0] for tup in low_risk])\n",
    "    low_risk_time = np.array([tup[1] for tup in low_risk])\n",
    "    \n",
    "    if len(low_risk) > 0 and len(high_risk) > 0:\n",
    "        # Calculate the Kaplan-Meier estimates for the two groups\n",
    "        time_high, survival_prob_high = kaplan_meier_estimator(high_risk_event.astype(bool), high_risk_time)\n",
    "        time_low, survival_prob_low = kaplan_meier_estimator(low_risk_event.astype(bool), low_risk_time)\n",
    "        \n",
    "        # Compute P-value combined data\n",
    "        results_pvalue_combined = logrank_test(low_risk_time, high_risk_time,\n",
    "                                               event_observed_A=low_risk_event, event_observed_B=high_risk_event)\n",
    "        pvalue_combined = results_pvalue_combined.p_value\n",
    "\n",
    "        # Compute c-index combined data\n",
    "        event_combined = np.array([tup[0] for tup in y_combined])\n",
    "        time_combined = np.array([tup[1] for tup in y_combined])\n",
    "        results_cindex_combined = concordance_index_censored(event_combined.astype(bool), time_combined, risk_scores_combined)\n",
    "        c_index_combined = results_cindex_combined[0]\n",
    "        \n",
    "        kmf1 = KaplanMeierFitter()\n",
    "        kmf2 = KaplanMeierFitter()\n",
    "        \n",
    "        kmf1.fit(high_risk_time.astype('float') / 365, high_risk_event, label='High Risk')\n",
    "        \n",
    "        kmf2.fit(low_risk_time.astype('float') / 365, low_risk_event, label='Low Risk')\n",
    "    \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        ax = kmf1.plot(color='r', label='High Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
    "        ax = kmf2.plot(color='g', label='Low Risk',show_censors=True, censor_styles={'ms': 6, 'marker': '|'})\n",
    "        plt.title(\"Kaplan-Meier Survival Curve\", fontsize=font_label, fontweight='bold')\n",
    "        plt.xlabel(\"Time (Years)\", fontsize=font_label, fontweight='bold')\n",
    "        plt.ylabel(\"Survival probability\", fontsize=font_label, fontweight='bold')\n",
    "        plt.xticks(np.arange(int(years.min()), int(years.max()) + 1, 1.0))\n",
    "        plt.yticks(np.arange(0.0, 1.0, 0.1))\n",
    "        ax.grid(axis='both', which='both', color='lightgray', linestyle='-', linewidth=0.5,zorder=-1000)\n",
    "        \n",
    "        add_at_risk_counts(kmf1, kmf2 , ax=ax)\n",
    "        # plt.tight_layout()\n",
    "        \n",
    "        fig.savefig(os.path.join('Plots', 'CWGBSA_{}-KaplanMier.jpg'.format(str(result_names[index_name]))), dpi=300)\n",
    "\n",
    "    #########################################################################################################\n",
    "\n",
    "    # Add Reported Results to its Data Frame\n",
    "    df_reported_results_cwgbsa.loc[len(df_reported_results_cwgbsa)] = [result_names[index_name], 'CWGBSA', mean_cindex_internal, std_cindex_internal,\n",
    "                                                                       mean_cindex_external, std_cindex_external, p_value_train, pvalue_external,\n",
    "                                                                       c_index_combined, pvalue_combined]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67efdd3-a996-477b-83b1-a1147285785d",
   "metadata": {},
   "source": [
    "# Save All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec134f68-615e-4252-9799-20b98b8c8db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all results along rows\n",
    "df_all_results = pd.concat([df_reported_results_rsf, df_reported_results_fssvm, df_reported_results_cwgbsa], axis=0, ignore_index=True)\n",
    "df_all_results.to_csv(os.path.join('Results', 'All Reported Results.csv'))\n",
    "df_all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2a1df-3f5d-4de0-96c8-dbee409cb55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
